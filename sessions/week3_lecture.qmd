---
title: "Hypothesis Testing"
subtitle: "Establishing and evaluating research hypotheses"
author: 
  - name: "Beatrice Taylor"
email: "beatrice.taylor@ucl.ac.uk"
date-as-string: "8th October 2025"
from: markdown+emoji
format: revealjs
---

# Last week
**Overview of lecture 2**

Continued concepts from exploratory data analysis, in particular probability distributions. 

- Representative data 
- Normal distribution
- Binomial distribution 
- Poisson distribution 
- Exponentials 
- Logarithms 

# This week 

## Motivation
**How do we understand how likely events are to occur?** 

*Question*

::: {.fragment .highlight-red}
What is the probability of someone at UCL being over 190cm?
:::

*Answer*

Try to understand the distribution of heights. 

::: {.notes}
Last week we asked this question and we thought about the distribution of the data. How to describe the distribution of the data mathematically.

This week we look at how to properly ask the research question, and how to answer it.  
:::

## The scientific method 

<div style="text-align:center;">
  <img src="L3_images/scientific_method.png" alt="The scientific method" style="max-width:60%">
</div>

::: {.notes}
Last week we looked at exploratory data analysis - now the formal process of coming up with and evaluating questions - very much part of the scientific method.

This lecture thinking about posing and answering research questions. Research science is all about coming up with hypotheses and evaluating them!

We see stories in the news, how do we know what to believe and what not to believe? This is where having an understanding of statistical tests can help us - we can evaluate claims to try and figure out which are/ aren't statistically significant.

Statisitical tests are frequently used in science to figure out if our findings are important or not - essentially a way to formally define a threshold of what is an interesting result vs, what isn't an interesting result. 

A clearly defined, and reproducible way to evaluate findings. 
:::

## Learning Objectives
By the end of this lecture you should be able to:

::: {.incremental}
1. Establish a hypothesis for a given research project. 
2. Define the Type I and Type II errors. 
3. Evaluate a hypothesis using appropriate statistical tests. 
:::

# How do you come up with a hypothesis? 

## Research question vs. hypothesis 

[**Research question**]{style="color:#49a0c4"} 

A research *question* focuses on a specific problem.

. . .

[**Hypothesis**]{style="color:#49a0c4"} 

A formal *statement* that you will seek to prove or disprove. 

::: {.notes}
The hypothesis is a statement you can explicitly test. It can either be true or false - and hence using evidence you can come to a judgement about it's truth value. 
::: 

## Flip a coin

:::: {.columns}

::: {.column width="50%"}

::: {.incremental}
- You have a coin. 
- You think it's a fair coin. 
- You toss it 10 times. 
- It comes up heads 7 times. 
:::

:::

::::

. . .

What do you think is the hypothesis here? 

::: {.notes}
WHich of these is something you can test? 
:::

## The hypothesis

:::: {.columns}

::: {.column width="50%"}

- You have a coin. 
- [You think it's a fair coin.]{style="color:#49a0c4"} 
- You toss it 10 times. 
- It comes up heads 7 times. 

:::

::: {.column width="50%"}

<div style="background-color:#2e6260; color:white; padding:8px; border-radius:5px; margin-top:10px;"> 
The hypothesis is that it is a fair coin. </div>

:::

::::


## What research question can you ask?

:::: {.columns}

::: {.column width="50%"}

- You have a coin. 
- You think it's a fair coin. 
- You toss it 10 times. 
- It comes up heads 7 times. 

:::

::: {.column width="50%"}

::: {.fragment .strike}
Is it a fair coin? 
:::

::: {.fragment .strike}
What’s the probability that it’s fair?
:::

::: {.fragment .strike}
If the coin is fair, how likely would it be to see 7 heads out of 10 flips?
:::


:::

::::


## What research question should you ask?

:::: {.columns}

::: {.column width="50%"}

- You have a coin. 
- You think it's a fair coin. 
- You toss it 10 times. 
- It comes up heads 7 times. 

:::

::: {.column width="50%"}

**Correct formulation:** 

If the coin is fair, how likely would it be to see 7 heads out of 10 flips *or an even more extreme result?*

:::

::::

::: {.notes}
Interested in the probability of seeing the event or something even more extreme. 
:::

# Establishing and evaluating a Hypothesis 
In [five]{style="color:#49a0c4"} simple steps. 

## Step 1
**Define the null and alternative hypothesis**

. . .

[**$H_0$** - the null hypothesis]{style="color:#49a0c4"} 

- this is the "status quo"
- it is assumed to be true 

. . .

[**$H_1$** - the alternative hypothesis]{style="color:#49a0c4"} 

- your hypothesis
- it requires some evidence (i.e. data) to verify
- it directly contradicts the null hypothesis

::: {.notes}
Be careful in how the two are defined. Logically H_1 needs to directly contradict H_0. 

For example if my H_0 was everyone likes chocolate. H_1 couldn't be some people prefer biscuits - since in this situation both H_0 and H_1 can be true at the same time. H_1 would have to be that not everyone likes chocolate. 
:::

## Step 2
**Set your significance level $\alpha$**

[*The significance level is the threshold below which you reject the null hypothesis.*]{style="color:#49a0c4"} 

::: {.incremental}
- Decide what "too unlikely" means
- Common choice is 5% significance
  - $\alpha = 0.05$ 
  - This means that if we see evidence that would have less than a 5% chance of occurring under the null hypothesis, then we reject the null hypothesis. 
:::

## [WARNING]{style="color:#FF0000"}
Decide what "too unlikely" means **before you do the test**

:::: {.columns}

::: {.column width="60%"}

<div style="text-align:center;">
  <img src="L3_images/warning_sign.png" alt="Don't be an idiot." style="max-width:90%">
</div>

:::

::: {.column width="40%"}

- otherwise considered 'HARKing' 
  - **H**ypothesising 
  - **A**fter 
  - the 
  - **R**esults 
  - are 
  - **K**nown

:::

::::

::: {.notes}
It's important to decide on your significance level prior, as otherwise you might find an event which is significant at the 10% threshold and not at 5% - which could lead to bad scientific practise.

There's a balance - often we don't know what will be interesting - so you do some exploratory data analysis. But you shouldn't be fishing around for stuff - needs to be grounded in theory and literature. 
:::

## Step 3
**Identify the evidence**

::: {.incremental}
- This could mean collecting the data
- Or identifying a suitable existing dataset
  - Crucial that it's *suitable* - think about biased/ unrepresentative data 
:::

::: {.notes}
In quant methods this normally means finding an open public dataset to use. 

The evidence needs to be suitable to answer the question - think about biased/representative data from last week. Something they will be assessed on in the assessment. 
:::

## Step 4
**Calculate the p-value**
[*The p-value is the probability of seeing the evidence, or something even more extreme, if the null hypothesis is true.*]{style="color:#49a0c4"}

::: {.incremental}
- Calculated according to the appropriate statistical test
- The choice of test is determined by the research question and the data
:::

::: {.notes}
We'll come back to different types of statistical test later in the lecture
:::

## Step 5 
**Compare p-value with significance level**

::: {.incremental}
- p-value $> \alpha$ 
  - Evidence not that unlikely. 
  - Not enough evidence to reject $H_0$.
- p-value $\leq \alpha$ 
  - Evidence very unlikely. 
  - Reject $H_0$ and accept $H_1$.
:::

## The steps
In order to evaluate our hypothesis we just have to do the five steps:

::: {.incremental}
1. Define the null and alternative hypothesis
2. Set you significance level
3. Identify the evidence
4. Calculate the p-value
5. Compare p-value with hypothesis level
:::

# Types of error 
... where things can go wrong. 

## Type I error
[*The true null hypothesis is incorrectly rejected.*]{style="color:#49a0c4"} 

The null hypothesis is true, but you get a false positive leading to you rejecting the null hypothesis. 

This is also called a **false positive**. 

. . .

<br>

*Example:* In court a defendant is found guilty despite being innocent. 


## Type II error
[*The false null hypothesis is incorrectly accepted.*]{style="color:#49a0c4"} 

The null hypothesis is false, but you get a false negative result, leading you to accepting the null hypothesis. 

This is also called a **false negative**. 

. . .

<br>

*Example:* In court a defendant is found innocent despite being guilty.  


## Example: Mammograms

<div style="text-align: center;">
![](L3_images/mammogram_van_woman.avif){width="700"}
</div>

NHS offers breast cancer screening for all people with breasts between the ages of 50 and 70.

::: {.notes}
The idea is to screen all those in the population who are at high risk of breast cancer - in the hope they pick up results better. 

Whilst the tests are good they're not 100% accurate. 
:::

## Example: Screening outcomes 

$H_0:$ The individual doesn't have breast cancer. 

$H_1:$ The individual does have breast cancer. 

## Example: Evaluating the evidence

From [NHS digital](https://digital.nhs.uk/data-and-information/publications/statistical/breast-screening-programme/england---2020-21/qualitystatement3).

[False positive]{style="color:#abc766"} 

- In 2020-2021, $4.0%$ of those screened had an abnormal results and were referred for assessment. 
- Of these, $77.1%$ were found to not have breast cancer at follow up assessment. 
- Leading to a **false positive rate of $3.1%$.**

## Example: Evaluating the evidence

From [NHS digital](https://digital.nhs.uk/data-and-information/publications/statistical/breast-screening-programme/england---2020-21/qualitystatement3).

[False negative]{style="color:#abc766"} 

- Those who had a negative screening but did in fact have breast cancer.
- Harder to calculate the false negative rate, as they might be diagnosed with breast cancer at any later point in time. 
- Studies suggest the false negative rate could be as high as $20%$. 

::: {.notes}
False positive is bad as you might pursue a healthcare treatment which is unecessary.

False negative - in healthcare context this is the worst outcome - as goes undiagnosed and hence untreated. 
:::

## Matrix of errors 

<div style="text-align:center;">
  <img src="L3_images/error_matrix.png" alt="Error matrix" style="max-width:80%">
</div>

::: {.notes}
Possible outcomes form a matrix. Have two good outcomes, and two bad outcomes which we want to look out for (these are the Type I and Type II errors).

This is something to bear in mind when we look at evaluating our hypotheses. How good is our data, so how reliable is our outcome? 

Often this language is used when evaluating the outcomes of an ML classification model. Where we report the quality of a model in terms of its rate of false positives and false negatives. 
:::

# A good hypothesis or a bad hypothesis? 

## Understanding the literature and the context 
The hypothesis should not come out of thin air. 

. . .

Should consider: 

::: {.incremental}
- What do you know about the context? 
- What research have other people done? 
:::


## Asking ethical hypothesis questions 
It's important to not make unethical assumptions in choosing the hypothesis. 

. . .

**Example** 

[Police profiling](https://www.amnesty.org.uk/press-releases/uk-police-forces-supercharging-racism-crime-predicting-tech-new-report) - assumes a correlation between ethnicity and crime

- Use contextual knowledge
- Is this causation? 
- Or correlation linked to other factors?

## Correlation vs. Causation 

[**Correlation:** *Two variables are statistically related, as one changes so does the other.*]{style="color:#49a0c4"}

[**Causation:** *One variable influences the other variable to occur.*]{style="color:#49a0c4"}

. . .

<br>

Causation implies correlation. 

**BUT** correlation **does not** imply causation!

::: {.notes}
Lots of things can be correlated **BUT** it doesn't mean one event caused another. 
:::

## Aliens and librarians

<div style="text-align:center;">
  <img 
    src="L3_images/spurious_hawaii_ufo.png" 
    alt="Spurious correlation - aliens and librarians" 
    style="width:800px">
  <div style="font-size:0.8em; color: #555; margin-top:4px;">
    Image credit: [Spurious Correlations](https://www.tylervigen.com/spurious/correlation/19598_google-searches-for-report-ufo-sighting_correlates-with_the-number-of-librarians-in-hawaii)
  </div>
</div>

::: {.notes}
It's a dumb example but it's quite easy to find nonsense correlations between random variables. Can generate your own at the website spurious correlations.  
:::


## Correlation **IS NOT** causation 
You might not know whether events are correlated, or causing each other. 

. . .

<br>
**BUT**

. . .

<br>

The point of the hypothesis test is to test your idea – but you should use your contextual understanding to come up with plausible (and ethical) initial questions.

:::{.notes}
Will return to looking at the correlation between variables in week 5. 
:::

## The point of the scientific method

:::: {.columns}

::: {.column width="60%"}

<div style="text-align:center;">
  <img src="L3_images/scientific_method.png" alt="The scientific method" style="max-width:100%">
</div>


:::

::: {.column width="40%"}

It's a process

::: {.incremental}
- question 
- test 
- evaluate 
- ***REPEAT!***
:::

:::

::::

<!-- # Example: Height of students 
What is the probability of someone at UCL being over 6ft?

## Example - step 1
**Define the null and alternative hypothesis**

H0: Probability of injury has not changed. 

H1: Probability of injury has changed. 

## Example - step 2
**Set your significance level**

𝜶 = 0.05 

## Example - step 3
**Identify the evidence**

Dataset: heights of students 

## Example - step 4
**Calculate the p-value**

Aha! -->


# Example: students height
[*Research question*]{style="color:#49a0c4"}  
Are male and female students similar heights?  

[*Research hypothesis*]{style="color:#49a0c4"}  
Male and female students are different heights on average.

<!-- ## Example - context 

:::: {.columns}

::: {.column width="60%"}

<div style="text-align: center;">
![](L3_images/timmy_bike.jpg){width="700"}
</div>

:::

::: {.column width="40%"}

::: {.incremental}
- UK gov reports cycling fatalities per year 
- Lime bikes introduced to the UK in 2021 
:::

:::

:::: -->


## Example - step 1

**Define the null and alternative hypothesis**

. . .

$H_0$: The mean height of male and female students is the same.

$H_1$: The mean height of male and female students is different.


## Example - step 2
**Set your significance level**

. . .

$\alpha = 0.05$ 

## Example - step 3
**Identify the evidence**

. . .

<br>

I've collected data from 198 students, as follows: 

| Group | Sample Size | Mean (cm) | std (cm) |
|-------|------------------|-----------------|-------------------|
| Female students |  95 | 170 | 5 |
| Male students   | 103 | 180 | 6 | 


<!-- Group 1 – female students  
$\bar{x}_1 = 170$, $s_1 = 5$, $n_1 = 95$  

Group 2 – male students  
$\bar{x}_2 = 180$, $s_2 = 6$, $n_2 = 103$ -->

## Example - step 4
**Calculate the p-value**

Aha!

. . .


How do we do this? We need to know what statistical test to use! 

# Statistical tests 

## Parametric vs. Non-parametric tests

**Parametric tests**

- Assumptions about the distribution:
  - Normal distribution 
  - Independent and unbiased samples 
  - Equal/comparable variances 
  - Continuous data 

. . .

**Non-parametric tests**

- Typcially less assumptions on the distribution 
- Continuous or discrete data 

## Deciding on a test 

Sometimes it can be hard to figure out which statistical test to use. 

We're going to cover common tests useful in data analysis. But you might find this [flowchart](https://www.brookes.ac.uk/getmedia/bede726d-771d-461f-900b-a3526fc7e199/stats-flow-chart.pdf) or this [table](https://stats.oarc.ucla.edu/other/mult-pkg/whatstat/) helpful for understanding how different tests can be applied.

# Parametric tests 

## Student's T-test 

:::: {.columns}

::: {.column width="50%"}
[*Student's T-test is used to compare the mean of a dataset.*]{style="color:#49a0c4"} 

::: {.incremental}
- parametric statistical test 
- assumes the data is normally distributed
:::

:::

::: {.column width="50%"}

<div style="text-align:center;">
  <img src="L3_images/William_Sealy_Gosset.jpg" alt="A photograph of William Sealy Gosset" style="max-width:70%;">
  <div style="font-size:0.8em; color: #555; margin-top:4px;">
    This is William Sealy Gosset - he was **not** a student.
    Image credit: https://en.wikipedia.org/wiki/William_Sealy_Gosset#/media/File:William_Sealy_Gosset.jpg
    
  </div>
</div>

:::

::::

::: {.notes}
William Gosset was working for Guinness brewing company when he came up with the t-test - but his company wanted his to publish under a pseudonym - hence 'student'. He was comparing the chemical properties of different samples of barley. 
:::

## Student's T-test: steps 

Calculate: 
:::{incremental}
- test statistic (called the t value)
  - [*The test statistic is a number that summarises the data so as to determine whether to reject the null hypothesis.*]{style="color:#49a0c4"} 
- degrees of freedom 
  - [*The number of degrees of freedom is the number of values in the final calculation that are free to vary.*]{style="color:#49a0c4"}
:::

. . . 

Which we use to identify the p value - typically using a 'look up table'. 

## Student's T-test: types 

<div style="text-align:center;">
  <img src="L3_images/t_tets_types.webp" alt="Types of T-tests" style="max-width:80%;">
  <div style="font-size:0.8em; color: #555; margin-top:4px;">
    Image credit: https://www.geeksforgeeks.org/data-science/t-test/
    
  </div>
</div>

## Student's T-test: one sample
[*Tests whether the population mean is equal to a specific value or not*]{style="color:#49a0c4"} 

. . .

The test statistic is calculated as: 

```{=tex}
\begin{align}
t = \frac{\bar{x} - \mu_{0}}{s / \sqrt{n}}
\end{align}
```

where

- $\bar{x}$ is the sample mean
- $\mu_{0}$ is the hypothesised population mean
- $s$ is the sample standard deviation
- $n$ is the sample size

## Student's T-test: one sample, degrees of freedom
[*The number of degrees of freedom is the number of values in the final calculation that are free to vary.*]{style="color:#49a0c4"}

```{=tex}
\begin{align}
df = n-1
\end{align}
```

<!-- ## Student's T-test: degrees of freedom 


In Student's T-Test with one sample the degrees of freedom are: 

```{=tex}
\begin{align}
df = n -1
\end{align}
``` -->

## Student's T-test: two sample 
[*Tests if the population means for two different groups are equal or not.*]{style="color:#49a0c4"}

. . .

The test statistic is:

```{=tex}
\begin{align}
t = \frac{\bar{x}_1 - \bar{x}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
\end{align}
```

- $\bar{x}_1, \bar{x}_2$ are the sample means of groups 1 and 2
- $n_1, n_2$ are the sample sizes of groups 1 and 2
- $s_p$ is the pooled standard deviation

. . .

```{=tex}
\begin{align}
s_p = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
\end{align}
```

with $s_1, s_2$ the sample standard deviations.

## Student's T-test: two sample, degrees of freedom 
[*The number of degrees of freedom is the number of values in the final calculation that are free to vary.*]{style="color:#49a0c4"}

In the two-sample Student's T-test the degrees of freedom are:

```{=tex}
\begin{align}
df = n_1 + n_2 - 2
\end{align}
```

## Student's T-test: paired 
[*Tests if the difference between paired measurements for a population is zero or not - normally used with longitudinal data.*]{style="color:#49a0c4"} 

. . .

The test statistic is: 
```{=tex}
\begin{align}
t = \frac{\bar{d}}{s_d / \sqrt{n}}
\end{align}
```

where

- $\bar{d}$ is the mean of the paired differences
- $s_d$ is the standard deviation of the paired differences
- $n$ is the number of pairs
- the number of degress of freedom is $n-1$

::: {.notes}
For example used when I have data from different years, and want to figure out if there's a difference across the years. 

You need to be able to pair the data - i.e. the same things being observed at time point 1 and time point 2. 
:::

## How many tails? 

Tests can be one-tailed or two-tailed - which you want is determined when you define the hypothesis.

<div style="text-align:center;">
  <img src="L3_images/one_vs_two_tailed.png" alt="Normal distribution with one vs two tails." style="max-width:100%">
</div>

*One tailed:* if you only care is the mean is significant in one direction

*Two tailed:* if you care about the mean being different regardless of direction 

<!-- ## Regression T-tests

Is the gradient non-zero?

This indicates a correlation between the two variables. 

...

This will be covered further in lecture X on linear regression.  -->


# Non-parametric tests 

## Kolmogorov-Smirnov

:::: {.columns}

::: {.column width="60%"}

<div style="text-align:center;">
  <img src="L3_images/overlayed_histograms.png" alt="Histograms of two different datasets." style="max-width:100%">
</div>


:::

::: {.column width="40%"}

::: {.incremental}
- Compares two probability distributions 
- Can be used to test whether an observed sample came from a given distribution 
- Or to test whether two samples both came from the same distribution
:::

:::

::::

::: {.notes}
Named after two Russian soviet mathematicians working in the mid 20th century
::: 


## K-S test: one sample test

The Kolmogorov–Smirnov test statistic is:

```{=tex}
\begin{align}
D_n = \sup_x \, | F_n(x) - F(x) |
\end{align}
```

where

- $F_n(x)$ is the empirical distribution function (EDF) of the sample
- $F(x)$ is the cumulative distribution function (CDF) of the reference distribution

. . .

<div style="background-color:#2e6260; color:white; padding:8px; border-radius:5px; margin-top:10px;"> <em>Note</em> 

\n '$sup$' is the suprenum - think of it as the smallest upper bound. </div>

## K-S: empirical distribution function 

The empirical distribution function (EDF) is:  

```{=tex}
\begin{align}
F_{n}(x) = \frac{1}{n} \sum_{i=1}^{n} 1_{(-\infty ,x]}(X_{i})
\end{align}
```

where

- $n$ is the number of observations
- $X_i$ are the ordered sample values
- $1_{(-\infty ,x]}(X_{i})$ is an indicator function (1 if $X_i \leq x$, else 0)

## K-S test: two sample test 

For the two-sample test:
```{=tex}
\begin{align}
D_{n,m} = \sup_x \, | F_n(x) - G_m(x) |
\end{align}
```
where 

- $F_n(x)$ and $G_m(x)$ are the EDFs of the two samples.

## K-S test: decision rule

The hypotheses would be: 

- $H_0$: the distributions are the same
- $H_1$: the distributions differ

. . .

Larger values of the test statistic $D$ is stronger evidence against $H_0$. 

## Kernel density estimate (KDE)

::: {.incremental}
- Used to generate a smooth probability density function for a random variable dataset
- Useful for understanding the underlying distribution of a sample 
- Think of it as getting a smooth function to describe a histogram of data
- There are no assumptions about the prior distribution
:::

:::{.notes}
Remember from last week - the probability density function (PDF) describes the likelihood of different outcomes for a continuous random variable
:::

## KDE of simulated heights  

It's easy to fit a KDE to data in Python:

```{python}
#| echo: true
#| eval: false

import numpy as np
import pandas as pd 
from scipy.stats import gaussian_kde

# Supposing you have some data 
data = pd.read_csv('/path_to_data')

# Kernel Density Estimation
kde = gaussian_kde(data)
x_vals = np.linspace(100, 200, 100)
y_vals = kde(x_vals)
```

## KDE of simulated heights  

<div style="text-align:center;">
  <img src="L3_images/height_histogram_kde.png" alt="KDE of heights." style="max-width:90%">
</div>

## KDE use case

::: {.incremental}
- fit the KDE to two sample datasets
- compare visually 
- carry out non-parametric test - such as Kolmogorov-Smirnov
:::

# Example: students height

## Example - step 1, 2, 3
**Define the null and alternative hypothesis**

$H_0$: The mean height of male and female students is the same.

$H_1$: The mean height of male and female students is different.

. . .

**Set your significance level**

$\alpha = 0.05$ 

. . .

**Identify the evidence**

Group 1 – female students  
$\bar{x}_1 = 170$, $s_1 = 5$, $n_1$ = 95  

Group 2 – male students  
$\bar{x}_2 = 180$, $s_2 = 6$, $n_2$ = 103

## Example - step 4
**Calculate the p-value**

- Use Student's T-test: two sample
  - don't care if students are taller or shorter - so use two-tailed test 
- Calculate the t value 
- Calculate the degress of freedom 
- Get the p value 

## Example - step 4 - calculate the t value

Substituting values:

```{=tex}
\begin{align}
s_p &= \sqrt{\frac{(95-1)\cdot 5^2 + (103-1)\cdot 6^2}{95+103-2}} \approx 5.55
\end{align}
```

Now compute $t-value$:

```{=tex}
\begin{align}
t &= \frac{170 - 180}{5.55 \cdot \sqrt{\tfrac{1}{95} + \tfrac{1}{103}}} \approx -12.7
\end{align}
```

:::{.notes}
Don't need to know the formulas because in practise we'll be using Python functions to do the calculations for us. 

Using the right python function is something we'll cover in todays tutorial. 
:::


## Example - step 4 - calculate the degrees of freedom 

For Student's T-Test we need degrees of freedom:  
```{=tex}
\begin{align}
df = n_1 + n_2 - 2 = 95 + 103 - 2 = 196
\end{align}
```

## Example - step 4 - calculate the p value 

Traditionally this uses look up tables - we're going to use Python. 

```{python}
#| echo: true
#| output: true 
from scipy import stats

t_val = -12.7
df = 18

# Two-tailed p-value
p_value_two_tailed = 2 * (1 - stats.t.cdf(abs(t_val), df))

print("Two-tailed p-value:", p_value_two_tailed.round(2))
```

## Example - step 4 - *simplified* 

We can do all the previous calulations in one step using the `scipy' library - we'll practise this in the tutorial.

## Example - step 5
**Compare p-value with hypothesis level**

Now we need to compare the p-value to our siginificance level. 

p-value = $2.8x10^{-10} < 0.05$ = alpha

. . .

...we reject $H_0$!

. . .

And conclude that male and female students have significantly different heights.

# Overview 
We've covered: 

- What makes a good hypothesis 
- How to formally state a hypothesis 
- Types of statistical tests 


# Practical 
The practical will focus on establishing and evaluating a research hypothesis. 

. . .

Have questions prepared!